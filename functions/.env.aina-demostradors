# Project Configuration
PROJECT_ID=aina-demostradors

# BigQuery Dataset Configuration
USE_BIGQUERY=true
BQ_DATASET=aina_logs_prod

# Local LanguageTool (Docker)
# Use http://host.docker.internal:8010 when running Functions inside Docker
# Use http://localhost:8010 when running Firebase emulator natively on Mac
# LANGUAGETOOL_URL=http://localhost:8010

# LanguageTool Container URL (Cloud Run)
# Replace with your actual Cloud Run URL after deployment
#LANGUAGETOOL_URL=https://languagetool-catalan-xxxxx-ew.a.run.app
LANGUAGETOOL_URL=https://languagetool-catalan-6h4rxyk5ca-ez.a.run.app

# RAG Service
RAG_SERVICE_URL=https://aina-rag-service-6h4rxyk5ca-ez.a.run.app

# Storage Bucket
STORAGE_BUCKET=aina-demostradors.firebasestorage.app

# anonimize prompts in BigQuery
BQ_ANONYMIZE_PII=true


# Context Window Strategy Configuration
# Auto-fallback: automatically switch to larger context models when limit exceeded
# DISABLED locally because ALIA/Gemini endpoints not available
CONTEXT_WINDOW_AUTO_FALLBACK=true
# Auto map-reduce: automatically chunk and process with map-reduce when context exceeded (FEATURE IN DEVELOPMENT - current fallback is to use local Salamandra 7B)
CONTEXT_WINDOW_AUTO_MAP_REDUCE=false
# Chunk size must fit: chunk + instruction + metadata < context_limit - output_tokens
# Salamandra: 4096 - 512 output = 3584 available. Instructions ~2000 tokens â†’ chunk ~1500 max
CONTEXT_WINDOW_DEFAULT_CHUNK_SIZE=1500
CONTEXT_WINDOW_DEFAULT_CHUNK_STRATEGY=paragraph
CONTEXT_WINDOW_DEFAULT_OVERLAP_TOKENS=100