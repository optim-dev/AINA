# =============================================================================
# Context Window Strategy Configuration
# =============================================================================
# These environment variables control how AINA handles context window limits
# for LLM models (Gemini, ALIA, Salamandra).
#
# Copy this to .env.local and customize as needed.
# =============================================================================

# -----------------------------------------------------------------------------
# AUTO-FALLBACK STRATEGY
# -----------------------------------------------------------------------------
# Enable automatic fallback to larger context models when prompt exceeds limit
# 
# When enabled (default):
#   - ALIA-16k → Gemini Flash (1M tokens)
#   - Salamandra-7B → ALIA-40B → Gemini Flash
#
# When disabled:
#   - Throws ContextWindowExceededError
#   - You must handle by manual model selection or map-reduce
#
# Values: "true" | "false"
# Default: "true"
CONTEXT_WINDOW_AUTO_FALLBACK=false

# -----------------------------------------------------------------------------
# MAP-REDUCE CHUNKING CONFIGURATION
# -----------------------------------------------------------------------------
# Default settings for map-reduce pattern when processing large documents

# Maximum tokens per chunk (including overlap)
# Recommended: 12000 for ALIA-16k (leaves 4k for output)
#             28000 for ALIA-32k (leaves 4k for output)
#             950000 for Gemini (leaves 50k for output)
# Default: 12000
CONTEXT_WINDOW_DEFAULT_CHUNK_SIZE=12000

# Chunking strategy for splitting documents
# - "sentence": Split at sentence boundaries (best for precise text)
# - "paragraph": Split at paragraph boundaries (best for structured docs)
# - "fixed": Fixed character-based splitting (fastest, may break sentences)
# Default: "paragraph"
CONTEXT_WINDOW_DEFAULT_CHUNK_STRATEGY=paragraph

# Number of tokens to overlap between chunks for context preservation
# Higher = more context preserved but more processing cost
# Recommended: 500-1000 tokens
# Default: 500
CONTEXT_WINDOW_DEFAULT_OVERLAP_TOKENS=500

# =============================================================================
# USAGE EXAMPLES
# =============================================================================

# Example 1: Disable auto-fallback, force explicit handling
# CONTEXT_WINDOW_AUTO_FALLBACK=false
# CONTEXT_WINDOW_DEFAULT_CHUNK_SIZE=12000
# CONTEXT_WINDOW_DEFAULT_CHUNK_STRATEGY=paragraph

# Example 2: Optimize for ALIA-32k endpoint
# CONTEXT_WINDOW_AUTO_FALLBACK=true
# CONTEXT_WINDOW_DEFAULT_CHUNK_SIZE=28000
# CONTEXT_WINDOW_DEFAULT_CHUNK_STRATEGY=paragraph
# CONTEXT_WINDOW_DEFAULT_OVERLAP_TOKENS=1000

# Example 3: Optimize for Gemini with large chunks
# CONTEXT_WINDOW_AUTO_FALLBACK=true
# CONTEXT_WINDOW_DEFAULT_CHUNK_SIZE=950000
# CONTEXT_WINDOW_DEFAULT_CHUNK_STRATEGY=fixed
# CONTEXT_WINDOW_DEFAULT_OVERLAP_TOKENS=10000

# Example 4: Conservative settings for cost optimization
# CONTEXT_WINDOW_AUTO_FALLBACK=true
# CONTEXT_WINDOW_DEFAULT_CHUNK_SIZE=8000
# CONTEXT_WINDOW_DEFAULT_CHUNK_STRATEGY=sentence
# CONTEXT_WINDOW_DEFAULT_OVERLAP_TOKENS=200

# =============================================================================
# RECOMMENDED CONFIGURATIONS BY USE CASE
# =============================================================================

# Use Case: Mixed document sizes (default)
# Best for: Production with unpredictable document sizes
# CONTEXT_WINDOW_AUTO_FALLBACK=true
# CONTEXT_WINDOW_DEFAULT_CHUNK_SIZE=12000
# CONTEXT_WINDOW_DEFAULT_CHUNK_STRATEGY=paragraph
# CONTEXT_WINDOW_DEFAULT_OVERLAP_TOKENS=500

# Use Case: Known large documents
# Best for: Processing contracts, tenders, specifications
# CONTEXT_WINDOW_AUTO_FALLBACK=true
# CONTEXT_WINDOW_DEFAULT_CHUNK_SIZE=28000
# CONTEXT_WINDOW_DEFAULT_CHUNK_STRATEGY=paragraph
# CONTEXT_WINDOW_DEFAULT_OVERLAP_TOKENS=1000

# Use Case: Cost optimization
# Best for: High-volume processing with budget constraints
# CONTEXT_WINDOW_AUTO_FALLBACK=false
# CONTEXT_WINDOW_DEFAULT_CHUNK_SIZE=8000
# CONTEXT_WINDOW_DEFAULT_CHUNK_STRATEGY=paragraph
# CONTEXT_WINDOW_DEFAULT_OVERLAP_TOKENS=200

# Use Case: Quality over cost
# Best for: Critical analysis requiring full context
# CONTEXT_WINDOW_AUTO_FALLBACK=true
# CONTEXT_WINDOW_DEFAULT_CHUNK_SIZE=950000
# CONTEXT_WINDOW_DEFAULT_CHUNK_STRATEGY=paragraph
# CONTEXT_WINDOW_DEFAULT_OVERLAP_TOKENS=5000

# =============================================================================
# MONITORING & OBSERVABILITY
# =============================================================================
# Check BigQuery logs to tune these settings:
#
# SELECT 
#   DATE(timestamp) as date,
#   COUNT(*) as total_requests,
#   SUM(CASE WHEN fallbackUsed THEN 1 ELSE 0 END) as fallback_count,
#   AVG(usage.totalTokens) as avg_tokens
# FROM `aina-demostradors.aina_logs_dev.llm_logs_v2`
# GROUP BY date
# ORDER BY date DESC
#
# If fallback_rate > 20%, consider:
# - Increasing CONTEXT_WINDOW_DEFAULT_CHUNK_SIZE
# - Using larger context endpoint by default
# - Implementing map-reduce for specific workflows
